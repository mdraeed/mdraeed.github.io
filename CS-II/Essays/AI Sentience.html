<!DOCTYPE html>
<html lang="en">
  <head>
    <title>MDR Portfolio - AI Sentience</title>
    <meta charset="UTF-8">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="apa2.css">   
  </head>
  <body>
    <h1>AI Sentience: The Dangerous Use of a Neutral Tool.</h1>
    <h2>MD Raeed</h2>
    <h2>Allen High School</h2>
    <h2>Computer Science II</h2>
    <h2>Professor Ben-Yaakov</h2>
    <h2>September 9, 2022</h2>
    <br>
    <h4> Introduction </h4>
    <p>In our rapidly fast-paced world, technology is advancing at a speed we’ve never seen before, and one of these technologies is AI. Artificial intelligence, made to mimic human intelligence and recreate it in non-living machines in order to achieve certain broad or specific goals. AI programs have been in existence since all the way back in 1951, a successful AI program was created by Christopher Stracey for the University of Oxford (Copeland, 1998). Back then however, it could only play a game of checkers. Nowadays, AI by companies such as Google, Apple, Tesla, and others can identify animals and humans in pictures to being able to drive a car.</p>
    <h4>Claim</h4>
    <p>But as all tools, AI is not specifically evil nor good, it is a neutral tool that humans have to manage. AI can be beneficial to society, from being able to regulate street traffic lights, operating public transport, being able to solve complex problems, etc. It can also have many negative effects, from being able to unemploy people to having the potential for getting out of control of humans, especially in military drones operated by AI. AI can provide numerous uses that are beneficial to society, but also harmful to society, if it is allowed to be.</p>
    <p>Exploring more on the topic of AI in the military, that is a debate that has been sparking recently, with the Department of Defense’s development of “automatic target recognition of personnel and vehicles from an unmanned aerial system using learning algorithms.” (Yanes, 2018). The debate is centered around whether or not AI should be allowed to control weapons of war that can kill humans. Regardless of opinions regarding whether it should or shouldn’t be, it can not be argued that AI does pose a significant risk, especially if it gets out of control of humans.</p>
    <h4> Conclusion </h4>
    <p>This is significant because it shows us that AI can be both beneficial and harmful, making it a neutral tool for humans to regulate and keep control of. With it having the potential to change the world for good, or worse.</p>
    <h4>References</h4>
    <p class="hangingindent">Yanes. (2018, May 8). Drones That Kill on Their Own: Will Artificial Intelligence Reach the Battlefield?<em>OpenMind</em>. Retrieved September 21, 2022, from https://www.bbvaopenmind.com/en/technology/artificial-intelligence/drones-that-kill-on-their-own-will-artificial-intelligence-reach-the-battlefield/</p>
    <p class="hangingindent">Copeland, B. J. C. (1998, July 20). Early Milestones in AI.<em>Encyclopedia Britannica.</em> Retrieved September 21, 2022, from https://www.britannica.com/technology/artificial-intelligence/Alan-Turing-and-the-beginning-of-AI</p>
    <p>    <a href="../index.html">Home Page.</a> </p>
</html>
